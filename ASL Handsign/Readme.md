# ğŸ–ï¸ Realtime ASL Alphabet Detection (Web-Based)

A web-based application for **real-time American Sign Language (ASL) alphabet recognition** using **MediaPipe Hand Landmark** and **K-Nearest Neighbor (KNN)** algorithm.
The entire training and prediction process runs **directly in the browser** without any backend server.

---

## âœ¨ Features

* ğŸ” Real-time hand detection using **MediaPipe Hands**
* ğŸ§  ASL alphabet classification using **KNN (K-Nearest Neighbor)**
* ğŸŒ Fully **web-based** (HTML, JavaScript, p5.js)
* ğŸ¥ Supports **external webcam** (e.g., DroidCam)
* ğŸ“Š Dataset split **80:20** for training and testing
* ğŸ§© Uses **21 hand landmarks (42 features)** per sample

---

## ğŸ§  Tech Stack

* **JavaScript (ES6)**
* **p5.js** â€“ rendering & webcam handling
* **MediaPipe Hands** â€“ hand landmark extraction
* **KNN Algorithm** â€“ classification
* **Python** â€“ dataset landmark extraction (offline)

---

## ğŸ“‚ Project Structure

```
project-root/
â”‚
â”œâ”€â”€ index.html          # Main web interface
â”œâ”€â”€ sketch.js           # Realtime ASL detection logic (KNN + MediaPipe)
â”œâ”€â”€ asl_landmarks.csv   # Extracted landmark dataset
â”œâ”€â”€ landmark_extract.py # Python script for landmark extraction
â””â”€â”€ README.md
```

---

## ğŸ“Š Dataset

* **Source**: ASL Alphabet Dataset (Kaggle)
* **Classes**: Aâ€“Z (static hand signs)
* **Features**: 21 hand landmarks (x, y) â†’ 42 features

Each image is processed using MediaPipe Hands and stored in CSV format before being loaded into the browser.

---

## âš™ï¸ How It Works

1. ASL images are processed using **MediaPipe Hands** to extract hand landmarks
2. Landmark coordinates are **normalized** relative to the wrist and hand scale
3. Data is split into **80% training** and **20% testing**
4. KNN model is trained **directly in the browser**
5. Webcam input is classified in real-time

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Download Dataset
https://www.kaggle.com/datasets/grassknoted/asl-alphabet
### 2ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/Zuuru/Computer-Vision/tree/72e794f347ec799f51114da604754423c4748d09/ASL%20Handsign
cd ASL Handsign
```

### 3ï¸âƒ£ Run with Live Server

Use **VS Code Live Server** or any local web server:

```bash
npx serve
```

> âš ï¸ Webcam access requires **HTTP server** (not file://)

---

## ğŸ“· Using External Camera (DroidCam)

1. Start **DroidCam** on your phone and PC
2. Open the web app in Chrome
3. Allow camera permission
4. Select **DroidCam Source** as the active camera

The app will automatically use it as the video input.

---

## ğŸ“ˆ Performance

* **Accuracy**: ~90% (static ASL letters)
* Best performance on: A, B, C, O, Y
* Challenging letters: M, N, R (similar hand shapes)
* Dynamic letters (J, Z) are **not supported**

---

## âš ï¸ Limitations

* Only supports **static ASL alphabets**
* Sensitive to lighting and hand orientation
* KNN performance depends on dataset balance

---

## ğŸ”® Future Improvements

* Add temporal models (LSTM) for dynamic signs
* Improve prediction stability (temporal smoothing)
* Add confidence score visualization
* Extend to word and sentence recognition

---

## ğŸ“š References

* Google MediaPipe Documentation
* Kaggle â€“ ASL Alphabet Dataset
* Cover, T. & Hart, P. (1967). Nearest Neighbor Pattern Classification

---

## ğŸ‘¤ Author

**Name**: *Zulfikri Arya*
**Institution**: *Semarang State Polytechnics*
**Year**: 2025

---

Read Here
https://docs.google.com/document/d/17k_K_H_8d2mkQRR-Zj8_kErpMfTHJh53/edit?usp=sharing&ouid=114661000494467937234&rtpof=true&sd=true
